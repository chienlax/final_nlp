# =============================================================================
# Development Config - Whisper (RTX 2050 4GB)
# =============================================================================
# Minimal config for testing pipeline on low-VRAM GPU

# Model
model:
  name: "openai/whisper-tiny"
  type: "whisper"
  language: "vi"
  task: "both" # multitask: ASR + ST

# Training - Conservative for 4GB VRAM
training:
  batch_size: 1
  gradient_accumulation_steps: 4
  # Effective batch size: 8

  learning_rate: 1.0e-4
  lr_scheduler_type: "linear"
  warmup_ratio: 0.1
  weight_decay: 0.01
  max_grad_norm: 1.0

  num_train_epochs: 2
  max_steps: 100 # Quick test run

  fp16: true
  gradient_checkpointing: true # Essential for 4GB

  eval_steps: 25
  save_steps: 50
  logging_steps: 10

# DataLoader - Conservative
dataloader:
  num_workers: 2
  pin_memory: true
  prefetch_factor: 2

# Output
output:
  dir: "training/outputs/dev_whisper"
  experiment_name: "whisper_tiny_dev"
