# Vietnamese-English Code-Switching Speech Translation

End-to-End Speech Translation pipeline for Vietnamese-English Code-Switching data. Downloads audio from **YouTube**, processes with **Gemini 2.5 Flash** for transcription + translation, and includes human-in-the-loop review via **Streamlit**.

---

## Features

- âœ… **YouTube Audio Ingestion**: Download and chunk videos as 16kHz mono WAV
- âœ… **DeepFilterNet Denoising**: Optional background noise removal
- âœ… **Gemini 2.5 Flash Processing**: Multimodal transcription + translation with min:sec.ms timestamps
- âœ… **Streamlit Review App**: Web UI with pagination, caching, light/dark mode, reviewer assignment
- âœ… **SQLite Database**: Lightweight storage with `review_state` workflow tracking
- âœ… **Tailscale Remote Access**: Secure remote access to review interface
- âœ… **DVC Integration**: Google Drive versioning for data artifacts

---

## Quick Start (5 Minutes)

### 1. Setup

```powershell
# Clone repository
git clone <repo-url>
cd final_nlp

# Run setup script (creates venv, installs deps, initializes DB)
.\setup.ps1

# Activate environment
.\.venv\Scripts\Activate.ps1
```

**Prerequisites:** Python 3.10+, FFmpeg, Gemini API key in `.env`

### 2. Process a YouTube Video

```powershell
# Download audio
python src/ingest_youtube.py "https://www.youtube.com/watch?v=VIDEO_ID"

# Chunk into 6-minute segments
python src/preprocessing/chunk_audio.py --video-id VIDEO_ID

# Optional: Denoise with DeepFilterNet
python src/preprocessing/denoise_audio.py --all

# Transcribe and translate
python src/preprocessing/gemini_process.py --video-id VIDEO_ID
```

### 3. Review in Streamlit

```powershell
# Start web interface
streamlit run src/review_app.py

# Access at http://localhost:8501
# Features: audio playback, timestamp editing, reviewer assignment, bulk operations
```

### 4. Export Dataset

```powershell
# Export approved segments to HuggingFace format
python src/export_final.py
# Output: data/export/<timestamp>/ with WAV files + manifest.tsv
```

---

## Documentation

| File | Purpose |
|------|---------|
| **[WORKFLOW.md](docs/WORKFLOW.md)** | Complete workflow guide, commands, troubleshooting |
| **[DEVELOPER.md](docs/DEVELOPER.md)** | Architecture, API reference, database schema, limitations |
| [CHANGELOG.md](CHANGELOG.md) | Project updates and migration notes |

---

## Project Structure

```
final_nlp/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingest_youtube.py         # Download YouTube audio
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â”œâ”€â”€ chunk_audio.py        # Split audio into 6-min chunks
â”‚   â”‚   â”œâ”€â”€ denoise_audio.py      # DeepFilterNet noise removal
â”‚   â”‚   â””â”€â”€ gemini_process.py     # Gemini transcription/translation
â”‚   â”œâ”€â”€ review_app.py             # Streamlit review interface
â”‚   â”œâ”€â”€ export_final.py           # Export final dataset
â”‚   â””â”€â”€ db.py                     # SQLite utilities
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ lab_data.db               # SQLite database (WAL mode)
â”‚   â”œâ”€â”€ raw/audio/                # Downloaded YouTube audio
â”‚   â”œâ”€â”€ raw/chunks/               # Chunked audio segments
â”‚   â””â”€â”€ export/                   # Exported datasets
â”œâ”€â”€ docs/                         # Documentation
â”œâ”€â”€ init_scripts/                 # SQL schema + migrations
â””â”€â”€ setup.ps1                     # Automated setup script
```

---

## Tech Stack

- **Audio Processing**: FFmpeg, pydub, DeepFilterNet
- **AI**: Google Gemini 2.5 Flash (multimodal API)
- **Database**: SQLite with WAL mode
- **UI**: Streamlit with custom CSS (light/dark mode)
- **Data Versioning**: DVC + Google Drive remote
- **Networking**: Tailscale for remote access

---

## Current Status

**Model**: `gemini-2.5-flash-preview-09-2025`  
**Timestamp Format**: `min:sec.ms` (e.g., `0:04.54`, `1:23.45`)  
**Database Schema**: Migrated with `review_state` column (`pending`/`reviewed`/`approved`/`rejected`)  
**Performance**: Cached queries (10-60s TTL), pagination (25 segments/page)  
**UI**: Light/dark mode support, reviewer assignment, audio refinement tab

See [CHANGELOG.md](CHANGELOG.md) for recent updates.

**Note:** Denoising is optional and keeps state as `pending`. See [Complete Workflow Guide](docs/08_complete_workflow.md) for details.

---

## Project Structure

```
final_nlp/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ lab_data.db             # SQLite database
â”‚   â”œâ”€â”€ raw/audio/              # Raw audio from YouTube
â”‚   â”œâ”€â”€ raw/chunks/             # Chunked audio for long videos
â”‚   â”œâ”€â”€ denoised/               # Denoised audio files
â”‚   â”œâ”€â”€ segments/               # Processed segment audio
â”‚   â””â”€â”€ export/                 # Final dataset output
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db.py                   # SQLite utilities
â”‚   â”œâ”€â”€ ingest_youtube.py       # YouTube ingestion
â”‚   â”œâ”€â”€ review_app.py           # Streamlit review app
â”‚   â”œâ”€â”€ export_final.py         # Dataset export
â”‚   â””â”€â”€ preprocessing/
â”‚       â”œâ”€â”€ chunk_audio.py      # Audio chunking for long videos
â”‚       â”œâ”€â”€ gemini_process.py   # Transcription + translation
â”‚       â””â”€â”€ denoise_audio.py    # DeepFilterNet denoising
â”œâ”€â”€ init_scripts/
â”‚   â””â”€â”€ sqlite_schema.sql       # Database schema
â”œâ”€â”€ docs/                       # Documentation
â”œâ”€â”€ setup.ps1                   # Setup script
â”œâ”€â”€ docker-compose.yml          # Optional Docker services
â””â”€â”€ requirements.txt            # Python dependencies
```

---

## Audio Specifications

| Parameter | Value |
|-----------|-------|
| Sample Rate | 16 kHz |
| Channels | Mono |
| Format | WAV (PCM 16-bit) |
| Video Duration | 2-60 minutes (input) |
| Segment Duration | 2-25 seconds (output) |
| Chunking | 10-min chunks, 10s overlap |

---

## Service Ports

| Service | Port | URL |
|---------|------|-----|
| Streamlit | 8501 | http://localhost:8501 |

---

## Database Synchronization (Team Collaboration)

For team collaboration between development and lab machines, we use **DVC (Data Version Control)** with Google Drive as the remote storage.

### Quick Sync Commands

```powershell
# Pull latest database from team
python -m dvc pull

# Push local database updates to team
python -m dvc add data/lab_data.db
git add data/lab_data.db.dvc data/.gitignore
git commit -m "Update database with new annotations"
python -m dvc push
git push
```

### Workflow Summary

1. **Dev Machine**: Ingest/process videos â†’ commit â†’ push via DVC
2. **Lab Machine**: Pull via DVC â†’ run Streamlit for annotation â†’ push updates back
3. **Automated Backups**: Hourly snapshots to `data/db_sync/backups/`

ðŸ“– **Full sync guide**: [docs/09_database_sync.md](docs/09_database_sync.md)

---

## License

MIT License
