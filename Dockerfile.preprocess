# =============================================================================
# Dockerfile.preprocess
# GPU-enabled container for audio preprocessing pipeline
#
# Tools:
#   - Gemini 2.5 Pro: Transcription + translation via API
#   - DeepFilterNet: Background noise removal (GPU-accelerated)
#   - FFmpeg: Audio processing
#
# Note: GPU required for DeepFilterNet (CUDA 12.4)
# =============================================================================

# PyTorch with CUDA 12.4 support
FROM pytorch/pytorch:2.5.1-cuda12.4-cudnn9-runtime

# Prevent interactive prompts during apt-get install
ENV DEBIAN_FRONTEND=noninteractive

# =============================================================================
# 1. Install System Dependencies
# =============================================================================
RUN apt-get update && apt-get install -y \
    # Audio processing
    ffmpeg \
    libsndfile1 \
    # Build tools (for some Python packages)
    build-essential \
    git \
    # Useful utilities
    wget \
    curl \
    # Clean up
    && rm -rf /var/lib/apt/lists/*

# =============================================================================
# 2. Set Working Directory
# =============================================================================
WORKDIR /app

# =============================================================================
# 3. Install Python Dependencies
# =============================================================================

# Core dependencies first
RUN pip install --no-cache-dir \
    # Gemini API for transcription/translation
    google-generativeai \
    # Streamlit for review app
    streamlit>=1.28.0 \
    # Audio processing
    librosa \
    soundfile \
    pydub \
    # Data handling
    numpy \
    pandas \
    # Utilities
    tqdm \
    pyyaml \
    python-dotenv \
    # Logging
    loguru

# DeepFilterNet for noise removal
RUN pip install --no-cache-dir \
    deepfilternet

# YouTube ingestion tools
RUN pip install --no-cache-dir \
    yt-dlp \
    youtube-transcript-api

# DVC for data versioning
RUN pip install --no-cache-dir \
    dvc[gdrive]

# =============================================================================
# 4. Create directories for data
# =============================================================================
RUN mkdir -p /app/data/raw/audio \
             /app/data/raw/text \
             /app/data/segments \
             /app/data/processed

# =============================================================================
# 5. Environment Variables
# =============================================================================
# HuggingFace cache (for WhisperX models)
ENV HF_HOME=/app/.cache/huggingface
ENV TRANSFORMERS_CACHE=/app/.cache/huggingface

# CUDA configuration
ENV CUDA_VISIBLE_DEVICES=0

# Python settings
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# =============================================================================
# 6. Health check
# =============================================================================
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')" || exit 1

# =============================================================================
# 7. Default command (keeps container alive for development)
# =============================================================================
CMD ["tail", "-f", "/dev/null"]

# =============================================================================
# Usage:
#   docker build -f Dockerfile.preprocess -t nlp-preprocess .
#   docker run --gpus all -v $(pwd):/app nlp-preprocess
#
# To run preprocessing scripts:
#   docker exec -it <container> python src/preprocessing/whisperx_align.py
# =============================================================================
